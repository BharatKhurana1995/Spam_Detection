{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5174074f",
   "metadata": {},
   "source": [
    "# This notebook shows use of various machine learning approaches for spam detection. The dataset used in this notebook has been downloaded from coursera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f7fb58",
   "metadata": {},
   "source": [
    "# Importing the required packages/libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8eaf8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\16178\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392f89e0",
   "metadata": {},
   "source": [
    "# Reading the data and partitioning into training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b2f0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data = pd.read_csv('spam.csv')\n",
    "spam_data['target'] = np.where(spam_data['target']=='spam',1,0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(spam_data['text'], spam_data['target'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb87bb09",
   "metadata": {},
   "source": [
    "# Training data and test data is vectorized using count vectorizer. Multinomial Naive Bayes classifier is trained and area under ROC curve is used as metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5d08e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve is 0.9720812182741116\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "mnb_clf = MultinomialNB(alpha=0.1).fit(X_train_vectorized, y_train)\n",
    "predictions = mnb_clf.predict(vectorizer.transform(X_test))    \n",
    "print(\"Area under ROC curve is\", roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5108d7c5",
   "metadata": {},
   "source": [
    "# Training data and test data is vectorized using Tfidf vectorizer. Multinomial Naive Bayes classifier is trained and area under ROC curve is used as metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f5a3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve is 0.9416243654822335\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=3)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "mnb_clf = MultinomialNB(alpha=0.1).fit(X_train_vectorized, y_train)\n",
    "predictions = mnb_clf.predict(vectorizer.transform(X_test))\n",
    "print(\"Area under ROC curve is\", roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d956b1c1",
   "metadata": {},
   "source": [
    "# Training data and test data is vectorized using Tfidf vectorizer. Number of characters in document is used as additional feature. SVC classifier is trained and area under ROC curve is used as metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ea0075b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve is 0.9661689557407943\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=5)\n",
    "X_train_vectorized = np.array(vectorizer.fit_transform(X_train).todense())\n",
    "X_train = X_train.to_frame()\n",
    "# Adding a feature for length of each document (No. of characters)\n",
    "X_train['length'] = X_train['text'].apply(lambda x: len(x))\n",
    "length_array_train = np.array(X_train['length'].tolist()).reshape(-1,1)\n",
    "# Stacking the new feature with training data\n",
    "X_train_extended = np.hstack((X_train_vectorized,length_array_train))\n",
    "X_test_vectorized = np.array(vectorizer.transform(X_test).todense())\n",
    "X_test = X_test.to_frame()\n",
    "# Adding feature for length of document for test data too\n",
    "X_test['length'] = X_test['text'].apply(lambda x: len(x))\n",
    "length_array_test = np.array(X_test['length'].tolist()).reshape(-1,1)\n",
    "# Stacking the new feature with test data\n",
    "X_test_extended = np.hstack((X_test_vectorized,length_array_test))\n",
    "# Converting arrays to sparse matrices\n",
    "X_train_extended = sparse.csr_matrix(X_train_extended)\n",
    "X_test_extended = sparse.csr_matrix(X_test_extended)\n",
    "clf = SVC(C=10000)\n",
    "clf.fit(X_train_extended, y_train)\n",
    "y_pred = clf.predict(X_test_extended)\n",
    "print(\"Area under ROC curve is\", roc_auc_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88ac8d2",
   "metadata": {},
   "source": [
    "# Training data and test data is vectorized using Tfidf vectorizer with word n-grams for n = 1 to 3. Number of characters in document and number of digits in document are used as additional features. Logistic regression classifier is trained and area under ROC curve is used as metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5240c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve is 0.9809793219360643\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(spam_data['text'], spam_data['target'], random_state=0)\n",
    "# Adding unigrams, bigrams and trigrams of words\n",
    "vectorizer = TfidfVectorizer(min_df=5, ngram_range=(1, 3))\n",
    "X_train_vectorized = np.array(vectorizer.fit_transform(X_train).todense())\n",
    "X_train = X_train.to_frame()\n",
    "# Adding length of document (No. of characters) as feature\n",
    "X_train['length'] = X_train['text'].apply(lambda x: len(x))\n",
    "length_array_train = np.array(X_train['length'].tolist()).reshape(-1,1)\n",
    "# Adding no. of digits in document as feature\n",
    "X_train['digit'] = X_train['text'].apply(lambda x: sum(c.isdigit() for c in x))\n",
    "digit_array_train = np.array(X_train['digit'].tolist()).reshape(-1,1)\n",
    "# Putting together all features in a numpy array\n",
    "X_train_extended = np.hstack((X_train_vectorized,length_array_train,digit_array_train))\n",
    "X_test_vectorized = np.array(vectorizer.transform(X_test).todense())\n",
    "X_test = X_test.to_frame() \n",
    "# Adding length of document (No. of characters) as feature\n",
    "X_test['length'] = X_test['text'].apply(lambda x: len(x))\n",
    "length_array_test = np.array(X_test['length'].tolist()).reshape(-1,1)\n",
    "# Adding no. of digits in document as feature\n",
    "X_test['digit'] = X_test['text'].apply(lambda x: sum(c.isdigit() for c in x))\n",
    "digit_array_test = np.array(X_test['digit'].tolist()).reshape(-1,1)\n",
    "# Putting together all features in a numpy array\n",
    "X_test_extended = np.hstack((X_test_vectorized,length_array_test,digit_array_test))\n",
    "# Converting arrays to sparse matrices\n",
    "X_train_extended = sparse.csr_matrix(X_train_extended)\n",
    "X_test_extended = sparse.csr_matrix(X_test_extended)\n",
    "clf = LogisticRegression(C=100)\n",
    "clf.fit(X_train_extended, y_train)\n",
    "y_pred = clf.predict(X_test_extended)\n",
    "print(\"Area under ROC curve is\", roc_auc_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3095bb3",
   "metadata": {},
   "source": [
    "# Function to combine new features into training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6daa0aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature(X, feature_to_add):\n",
    "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dee4de",
   "metadata": {},
   "source": [
    "# Training data and test data is vectorized using count vectorizer with character n-grams for n = 2 to 5. Number of characters in document, number of digits in document and number of non-word characters in document are used as additional features. Logistic regression classifier is trained and area under ROC curve is used as metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bcf3bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve is 0.9813973821367333\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(spam_data['text'], spam_data['target'], random_state=0)\n",
    "# Use character n grams to make model robust to spelling mistakes\n",
    "vectorizer = CountVectorizer(min_df=5, ngram_range=(2, 5), analyzer='char_wb')\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_train = X_train.to_frame()\n",
    "# Add features for length of document, no. of digits in document and no. of non-word characters in document\n",
    "ser1 = X_train['text'].apply(lambda x: len(x))\n",
    "ser2 = X_train['text'].apply(lambda x: sum(c.isdigit() for c in x))\n",
    "ser3 = X_train['text'].apply(lambda x: len(re.findall(r'\\W',x)))\n",
    "X_train_extended = add_feature(X_train_vectorized, [ser1, ser2, ser3])\n",
    "X_train_df = pd.DataFrame(X_train_extended.toarray())\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "X_test = X_test.to_frame() \n",
    "# Add features for length of document, no. of digits in document and no. of non-word characters in document\n",
    "ser4 = X_test['text'].apply(lambda x: len(x))\n",
    "ser5 = X_test['text'].apply(lambda x: sum(c.isdigit() for c in x))\n",
    "ser6 = X_test['text'].apply(lambda x: len(re.findall(r'\\W',x)))\n",
    "X_test_extended = add_feature(X_test_vectorized, [ser4, ser5, ser6])\n",
    "X_test_df = pd.DataFrame(X_test_extended.toarray())\n",
    "clf = LogisticRegression(C=100)\n",
    "clf.fit(X_train_extended, y_train)\n",
    "y_pred = clf.predict(X_test_extended)\n",
    "print(\"Area under ROC curve is\", roc_auc_score(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
